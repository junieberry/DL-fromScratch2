{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "13_word2vec.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNT5Y0PLjflYkVFl1GhCzXX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/junieberry/DL-fromScratch2/blob/main/03_word2vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90nF8XPy2q_6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1a918e7-8e37-48d2-b969-b4bcf046b4e5"
      },
      "source": [
        "cd /content/drive/MyDrive/밑시딥/deep-learning-from-scratch-2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/밑시딥/deep-learning-from-scratch-2'\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5GhJmIX2ram"
      },
      "source": [
        "import sys\n",
        "sys.path.append('..')\n",
        "from common.util import preprocess\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_aLxK512ski"
      },
      "source": [
        "\n",
        "\n",
        "def create_contexts_target(corpus, window_size=1):\n",
        "  target = corpus[window_size:-window_size]\n",
        "  contexts = []\n",
        "\n",
        "  for idx in range(window_size, len(corpus)-window_size):\n",
        "    cs = []\n",
        "    for t in range(-window_size, window_size + 1):      \n",
        "      if t == 0:    \n",
        "        continue      \n",
        "      cs.append(corpus[idx+t])\n",
        "    contexts.append(cs)\n",
        "\n",
        "  return np.array(contexts), np.array(target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nhs44lWF2uHe"
      },
      "source": [
        "from common.layers import MatMul, SoftmaxWithLoss\n",
        "\n",
        "class SimpleCBOW:\n",
        "  def __init__(self, vocab_size, hidden_size):\n",
        "    V, H = vocab_size, hidden_size\n",
        "\n",
        "    W_in=0.01*np.random.rand(V,H).astype('f')\n",
        "    W_out=0.01*np.random.rand(H,H).astype('f')\n",
        "\n",
        "    self.in_layer0=MatMul(W_in)\n",
        "    self.in_layer1=MatMul(W_in)\n",
        "    self.out_layer=MatMul(W_out)\n",
        "    self.loss_layer=SoftmaxWithLoss()\n",
        "\n",
        "    layers=[self.in_layer0, self.in_layer1, self.out_layer]\n",
        "    self.params, self.grads=[],[]\n",
        "    for layer in layers:\n",
        "      self.params+=layer.params\n",
        "      self.grads+=layer.grads\n",
        "\n",
        "    self.word_vecs=W_in\n",
        "  \n",
        "  def forward(self, contexts, target):\n",
        "    h0=self.in_layer0.forward(contexts[:,0])\n",
        "    h1=self.in_layer1.forward(contexts[:,1])\n",
        "    h=(h0+h1)*0.5\n",
        "    score=self.out_layer.forward(h)\n",
        "    loss=self.loss_layer.forward(score,target)\n",
        "    return loss\n",
        "\n",
        "  def backward(self, dout=1):\n",
        "    ds=self.loss_layer.backward(dout)\n",
        "    da=self.out_layer.backward(ds)\n",
        "    da+=0.5\n",
        "    self.in_layer1.backward(da)\n",
        "    self.in_layer0.backward(da)\n",
        "    return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0mUqZ_E2u9q"
      },
      "source": [
        "from common.trainer import Trainer\n",
        "from common.optimizer import Adam\n",
        "from common.util import convert_one_hot\n",
        "\n",
        "window_size = 1\n",
        "hidden_size = 5\n",
        "batch_size = 3\n",
        "max_epoch = 1000\n",
        "\n",
        "text = 'You say goodbye and I say hello.'\n",
        "corpus, word_to_id, id_to_word = preprocess(text)\n",
        "\n",
        "vocab_size = len(word_to_id)\n",
        "contexts, target = create_contexts_target(corpus, window_size)\n",
        "target = convert_one_hot(target, vocab_size)\n",
        "contexts = convert_one_hot(contexts, vocab_size)\n",
        "\n",
        "model = SimpleCBOW(vocab_size, hidden_size)\n",
        "optimizer = Adam()\n",
        "trainer = Trainer(model, optimizer)\n",
        "\n",
        "trainer.fit(contexts, target, max_epoch, batch_size)\n",
        "trainer.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srv3ZH9g2wJQ"
      },
      "source": [
        "word_vecs = model.word_vecs\n",
        "for word_id, word in id_to_word.items():\n",
        "  print(word, word_vecs[word_id])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}