{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "07_RnnlmGenerator.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1rTdeSljSQn0EXZlIAoR7NbkRqpEMbVDk",
      "authorship_tag": "ABX9TyNCQmsE6uRHx1Kx0EJDEyC2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/junieberry/DL-fromScratch2/blob/main/07_RnnlmGenerator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZEeSG8lTNmQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17c064c5-0bdb-474a-a255-03ef71933dbb"
      },
      "source": [
        "cd /content/drive/MyDrive/밑시딥/deep-learning-from-scratch-2"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/밑시딥/deep-learning-from-scratch-2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYJz8lne0zVA"
      },
      "source": [
        "## Rnnlm Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGMYRToqzJPm"
      },
      "source": [
        "import sys\n",
        "sys.path.append('..')\n",
        "from ch06.rnnlm import Rnnlm\n",
        "from common.functions import softmax\n",
        "from ch06.better_rnnlm import BetterRnnlm\n",
        "\n",
        "\n",
        "class RnnlmGen(Rnnlm):\n",
        "\n",
        "  ## start_id = 최초로 주는 단어의 id\n",
        "  ## sample_size = 샘플링하는 단어의 수\n",
        "  ## skip_ids = 전처리된 단어 (샘플링 ㄴ)\n",
        "  def generate(self, start_id, skip_ids=None, sample_size=20):\n",
        "    word_ids = [start_id]\n",
        "    x= start_id\n",
        "    while len(word_ids)<sample_size:\n",
        "      x = np.array(x).reshape(1,1)\n",
        "      score = self.predict(x)\n",
        "      p = softmax(score.flatten())\n",
        "\n",
        "      sampled = np.random.choice(len(p), size=1, p=p)\n",
        "      if (skip_ids is None) or (sampled not in skip_ids):\n",
        "        x = sampled\n",
        "        word_ids.append(int(x))\n",
        "\n",
        "    return word_ids"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOh4-IF31bs3"
      },
      "source": [
        "### 학습 수행 전\n",
        "my life is overdue crimes bookings bofors aims detailing pitch injured acquirer n't underscored kgb our frame steal works constant spencer predictable\n",
        "\n",
        "### 학습 수행 후\n",
        "my life is n't seen in good hurry may write at an end of each protests ahead.\n",
        " democratic shamir 's wheat\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDNWsRqT0yyC",
        "outputId": "aff186fa-885d-4dfc-a614-de0174b9dfef"
      },
      "source": [
        "from dataset import ptb\n",
        "from common.np import *\n",
        "import numpy as np\n",
        "\n",
        "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
        "vocab_size = len(word_to_id)\n",
        "corpus_size = len(corpus)\n",
        "\n",
        "model = RnnlmGen()\n",
        "model.load_params('./ch06/Rnnlm.pkl')\n",
        "\n",
        "## start words, skip words\n",
        "start_words = 'my life is'\n",
        "start_ids = [word_to_id[w] for w in start_words.split(' ')]\n",
        "\n",
        "skip_words = ['N', '<unk>', '$']\n",
        "skip_ids = [word_to_id[w] for w in skip_words]\n",
        "\n",
        "for x in start_ids[:-1]:\n",
        "  x = np.array(x).reshape(1,1)\n",
        "  model.predict(x)\n",
        "\n",
        "word_ids = model.generate(start_ids[-1], skip_ids)\n",
        "word_ids = start_ids[:-1] + word_ids\n",
        "txt = ' '.join([id_to_word[i] for i in word_ids])\n",
        "txt = txt.replace(' <eos>', '.\\n')\n",
        "print(txt)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "my life is n't seen in good hurry may write at an end of each protests ahead.\n",
            " democratic shamir 's wheat\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61Gvyn7H9Yhp"
      },
      "source": [
        "## Better Rnnlm Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEqKUkYu9YG-"
      },
      "source": [
        "class BetterRnnlmGen(BetterRnnlm):\n",
        "\n",
        "  def generate(self, start_id, skip_ids=None, sample_size=20):\n",
        "    word_ids = [start_id]\n",
        "    x= start_id\n",
        "    while len(word_ids)<sample_size:\n",
        "      x = np.array(x).reshape(1,1)\n",
        "      score = self.predict(x)\n",
        "      p = softmax(score.flatten())\n",
        "\n",
        "      sampled = np.random.choice(len(p), size=1, p=p)\n",
        "      if (skip_ids is None) or (sampled not in skip_ids):\n",
        "        x = sampled\n",
        "        word_ids.append(int(x))\n",
        "\n",
        "    return word_ids\n",
        "\n",
        "    def get_state(self):\n",
        "        states = []\n",
        "        for layer in self.lstm_layers:\n",
        "            states.append((layer.h, layer.c))\n",
        "        return states\n",
        "\n",
        "    def set_state(self, states):\n",
        "        for layer, state in zip(self.lstm_layers, states):\n",
        "            layer.set_state(*state)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IX0xs7G97ta"
      },
      "source": [
        "### 학습 수행 전\n",
        "my life is valuable front ig rebounding retaining employee slowing recall seek exceeds kim counter advertisers struck advantages institutes reckless pass organization\n",
        "\n",
        "### 학습 수행 후\n",
        "\n",
        "my life is that their investors gathered significant prospects of cheating during the past two days.\n",
        " recently the financially successful new"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMHtbbxk9y2M",
        "outputId": "4a08cfc6-7d9f-404e-833c-47a7a8d64fab"
      },
      "source": [
        "from dataset import ptb\n",
        "from common.np import *\n",
        "import numpy as np\n",
        "\n",
        "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
        "vocab_size = len(word_to_id)\n",
        "corpus_size = len(corpus)\n",
        "\n",
        "model = BetterRnnlmGen()\n",
        "model.load_params('./ch06/BetterRnnlm.pkl')\n",
        "\n",
        "## start words, skip words\n",
        "start_words = 'my life is'\n",
        "start_ids = [word_to_id[w] for w in start_words.split(' ')]\n",
        "\n",
        "skip_words = ['N', '<unk>', '$']\n",
        "skip_ids = [word_to_id[w] for w in skip_words]\n",
        "\n",
        "for x in start_ids[:-1]:\n",
        "  x = np.array(x).reshape(1,1)\n",
        "  model.predict(x)\n",
        "\n",
        "word_ids = model.generate(start_ids[-1], skip_ids)\n",
        "word_ids = start_ids[:-1] + word_ids\n",
        "txt = ' '.join([id_to_word[i] for i in word_ids])\n",
        "txt = txt.replace(' <eos>', '.\\n')\n",
        "print(txt)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "my life is that their investors gathered significant prospects of cheating during the past two days.\n",
            " recently the financially successful new\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}